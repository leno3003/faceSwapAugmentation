# faceSwapAugmentation
## Goal of this project
The goal of this project is to build a reliable data augmentation system,
which allows the user to create an unlimited number of clips, based on
a single starting video.
This method can be applied in every field which requires a large
amount of data, enabling the user to save plenty of time and money.

## Pipeline architecture
The pipeline uses an input video `data_dst.mp4`, which will be used as
a base upon which apply a face. This face, can be generated by AI, in
two different methods: stylegan2, or ThisPersonDoesNotExist.
The to-be-applied faces can also be gathered from a dataset. To this
matter, `KDEF face dataset` is suggested, but many others can be used.

The obtained result will strongly rely on two factors:
- Emotional variance
- Angle variance

## Installation and setup
Virual environments are managed with 
[Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/).
There are several virtual environments that are necessary for the
whole pipeline. A `.yml` file for each of those can be found under the
`envs` folder.
To create an environment from a `.yml` file, type:
`conda env create -f environment.yml`. This command must be run for
each file in the `envs` folder.
**Check all the submodule's repositories for further instruction
about the installation of each and single element of the pipeline.**

In order to use `KDEF` as face dataset, it must be placed in the
`faceSwapAugmentation` directory.
```
.
├── Deep3DFaceRecon_pytorch
├── DeepFaceLab_Linux
├── ***KDEF_and_AKDEF***
├── README.md
├── ThisPersonDoesNotExistAPI
├── TransformMeshToGIFSprite
├── framesEvaluation.py
├── lmDeep3DFR.py
├── pipelineAutomation.sh
├── stylegan2-ada-pytorch
└── swapQualityEvaluation

```
## Usage

The pipeline takes as input a video, called `data_dst.mp4`. This will
be the base video, upon which AI generated faces will be applied. All
the facial variations, emotions and expressions will be kept in the
resulting video. Other than `data_dst.mp4`, the pipeline takes in
input a second argument, which can be choosen from one of the
following:
- stylegan
- tpdne
- whole
- <path_to_imgs>

Choosing `stylegan`, the pipeline will generate a face using
[stylegan2-ada-pytorch](https://github.com/NVlabs/stylegan2-ada-pytorch/)
Example:
`./pipelineAutomation.sh -s stylegan -d test.mp4`

Choosing `tpdne`, the pipeline will generate a face using
[ThisPersonDoesNotExistAPI](https://github.com/David-Lor/ThisPersonDoesNotExistAPI)
Example:
`./pipelineAutomation.sh -s tpdne -d test.mp4`

Choosing `whole`, will be produced a face-swap video for each
individual in the `KDEF_and_AKDEF/KDEF/` folder.
Example:
`./pipelineAutomation.sh -s whole -d test.mp4`

Passing as `-s` argument a path to a folder, all the images in it will
be used in order to create the face swap video.
Example:
`./pipelineAutomation.sh -s img_folder/ -d test.mp4`

Generic usage:
`./pipelineAutomation.sh -s <src_path> -d <dst_path>`
